{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73996049-5075-45dc-87fe-3f7c4a8b97fc",
   "metadata": {},
   "source": [
    "### Task - 3 : Implement a support vector machine (SVM) to classify images of cats and dogs from the Kaggle dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29fd09d-e501-446f-a705-979bca6c34fb",
   "metadata": {},
   "source": [
    "## Libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "93f1f4c6-0698-42d2-ba7b-17043ebb1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5d8437aa-1ab3-47d5-8921-9ea08d0e180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = f\"Cat Dog Dataset/\"\n",
    "os.makedirs(folder_path, exist_ok = True)\n",
    "\n",
    "# define path\n",
    "confusion_image_path = os.path.join(folder_path, \"confusion matrix.png\")\n",
    "classification_file_path = os.path.join(folder_path, \"classification_report.txt\")\n",
    "model_file_path = os.path.join(folder_path, \"svm_model.pkl\")\n",
    "\n",
    "# Path dataset\n",
    "dataset_dir = \"Cat Dog Dataset/\"\n",
    "train_dir = \"Cat Dog Dataset/train\"\n",
    "test_dir = \"Cat Dog Dataset/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2ef6ad-2151-47db-b5d4-7e083f2db934",
   "metadata": {},
   "source": [
    "## Load the Data, Preprocessing data and labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "09297387-85d1-47d5-a1ec-5c5f35898e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess images from the train folder\n",
    "def preprocess_images(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        for filename in os.listdir(label_dir):\n",
    "            img = cv2.imread(os.path.join(label_dir, filename))\n",
    "            img = cv2.resize(img, (100,100))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            images.append(img)\n",
    "            labels.append(0 if label == \"cats\" else 1)\n",
    "\n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5da004a7-81e3-418e-b69e-f88919395e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = preprocess_images(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c3dd72ee-7b01-4d66-a8f8-dbc2451771bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train images and labels\n",
    "images = np.array(train_images)\n",
    "labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "dd04ac45-a2f8-43c2-9eef-689a9e7993b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[177, 174, 165, ..., 223, 135, 141],\n",
       "        [178, 173, 181, ..., 223, 140, 143],\n",
       "        [179, 169, 176, ..., 223, 137, 138],\n",
       "        ...,\n",
       "        [190, 188, 189, ..., 210, 201, 202],\n",
       "        [187, 183, 190, ..., 198, 194, 201],\n",
       "        [190, 189, 189, ..., 203, 200, 201]],\n",
       "\n",
       "       [[239, 239, 239, ...,  11,  11,  11],\n",
       "        [239, 239, 239, ...,  11,  11,  11],\n",
       "        [239, 239, 239, ...,  11,  11,  11],\n",
       "        ...,\n",
       "        [114, 114, 114, ...,  26,  25,  24],\n",
       "        [114, 110, 115, ...,  23,  22,  21],\n",
       "        [114, 106, 115, ...,  21,  20,  19]],\n",
       "\n",
       "       [[ 19,  20,  21, ...,  17,  17,  17],\n",
       "        [ 19,  20,  21, ...,  17,  17,  17],\n",
       "        [ 19,  20,  21, ...,  17,  17,  17],\n",
       "        ...,\n",
       "        [ 48,  51,  54, ...,  12,  12,  11],\n",
       "        [ 50,  53,  55, ...,  11,  11,  10],\n",
       "        [ 50,  54,  56, ...,  11,  11,  10]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 97, 131, 143, ...,  84,  84,  84],\n",
       "        [ 95, 118, 133, ...,  84,  83,  83],\n",
       "        [ 84,  98, 124, ...,  84,  82,  82],\n",
       "        ...,\n",
       "        [152, 161, 140, ..., 155, 101, 100],\n",
       "        [144, 160, 140, ..., 122,  98,  98],\n",
       "        [142, 152, 131, ...,  97,  98,  97]],\n",
       "\n",
       "       [[ 49,  44,  42, ...,  92,  87,  84],\n",
       "        [ 49,  46,  45, ...,  94,  95,  88],\n",
       "        [ 59,  59,  57, ...,  96,  96,  93],\n",
       "        ...,\n",
       "        [155, 155, 158, ..., 172, 168, 175],\n",
       "        [164, 145, 156, ..., 157, 159, 159],\n",
       "        [159, 151, 149, ..., 152, 156, 147]],\n",
       "\n",
       "       [[ 79,  88, 120, ..., 104, 100,  94],\n",
       "        [106,  92, 117, ...,  88,  81,  87],\n",
       "        [111,  98,  91, ..., 100,  83,  75],\n",
       "        ...,\n",
       "        [ 23,  31,  21, ...,  16,  13,  11],\n",
       "        [ 22,  23,  15, ...,  16,  12,  10],\n",
       "        [ 25,  19,  14, ...,  15,  11,   9]]], dtype=uint8)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "092c5b12-11ac-4cf7-a9f0-0273138b1085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2edeb616-b27f-4e10-9e56-39d911c0f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten images to use as feature\n",
    "X_train = images.reshape(len(images), -1)\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6e154365-344a-48a4-b5a0-8485760c678e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the SVM model\n",
    "\n",
    "svm = SVC(kernel = \"linear\",\n",
    "         C = 1.0,\n",
    "         random_state = 42)\n",
    "svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021715-3ede-4fcb-87b5-30cd46aa1586",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e6cabb93-bc0c-462a-9bd8-62d8760dcb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess test image\n",
    "def preprocess_test_images(directory):\n",
    "    test_images = []\n",
    "    test_filenames = []\n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory,label)\n",
    "        for filename in os.listdir(label_dir):\n",
    "            img = cv2.imread(os.path.join(label_dir, filename))\n",
    "            # cv2.imshow(\"abc\",img)\n",
    "            img = cv2.resize(img, (100,100))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            test_images.append(img)\n",
    "            test_filenames.append(filename)\n",
    "        \n",
    "    return test_images,test_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f0246442-52fc-436e-99ea-d8714b509e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess test Images\n",
    "test_images, test_filenames = preprocess_test_images(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5c183ec2-75e9-4565-9f9c-313976d60b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten test image\n",
    "X_test = np.array(test_images).reshape(len(test_images),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "510edfe2-13b6-47b4-837c-ddf52dd0819a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128, 139, 140, ...,  47,  47,  49],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [  0,   0,   0, ...,  14,   5,   6],\n",
       "       ...,\n",
       "       [173, 157, 168, ..., 182, 178, 169],\n",
       "       [194, 196, 198, ...,  42,  69,  56],\n",
       "       [101,  90,  85, ..., 168, 169, 168]], dtype=uint8)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0e7b152d-1229-4c96-838d-bbf4fef16bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for test set\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e5636c71-acff-46c6-a18a-0665f47237e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3c947105-ead6-4507-b53d-f254c96464c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map predictions to cat or dog and print them\n",
    "label_mapping = {0 : \"Cat\", 1 : \"Dog\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "07dc1f7a-d546-4e4a-b6c1-d92a188ea8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0456af87-10ad-47a5-8e29-5a7e32296639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the test dataset: \n",
      "File: cat_1.jpg, Prediction: Cat\n",
      "File: cat_106.jpg, Prediction: Cat\n",
      "File: cat_109.jpg, Prediction: Cat\n",
      "File: cat_113.jpg, Prediction: Cat\n",
      "File: cat_114.jpg, Prediction: Dog\n",
      "File: cat_116.jpg, Prediction: Cat\n",
      "File: cat_118.jpg, Prediction: Dog\n",
      "File: cat_119.jpg, Prediction: Dog\n",
      "File: cat_124.jpg, Prediction: Cat\n",
      "File: cat_140.jpg, Prediction: Dog\n",
      "File: cat_147.jpg, Prediction: Cat\n",
      "File: cat_156.jpg, Prediction: Cat\n",
      "File: cat_158.jpg, Prediction: Dog\n",
      "File: cat_162.jpg, Prediction: Cat\n",
      "File: cat_18.jpg, Prediction: Cat\n",
      "File: cat_190.jpg, Prediction: Cat\n",
      "File: cat_203.jpg, Prediction: Cat\n",
      "File: cat_223.jpg, Prediction: Dog\n",
      "File: cat_234.jpg, Prediction: Dog\n",
      "File: cat_244.jpg, Prediction: Cat\n",
      "File: cat_251.jpg, Prediction: Cat\n",
      "File: cat_255.jpg, Prediction: Dog\n",
      "File: cat_268.jpg, Prediction: Cat\n",
      "File: cat_279.jpg, Prediction: Cat\n",
      "File: cat_281.jpg, Prediction: Cat\n",
      "File: cat_290.jpg, Prediction: Cat\n",
      "File: cat_306.jpg, Prediction: Cat\n",
      "File: cat_313.jpg, Prediction: Cat\n",
      "File: cat_332.jpg, Prediction: Dog\n",
      "File: cat_341.jpg, Prediction: Dog\n",
      "File: cat_342.jpg, Prediction: Cat\n",
      "File: cat_355.jpg, Prediction: Dog\n",
      "File: cat_358.jpg, Prediction: Cat\n",
      "File: cat_371.jpg, Prediction: Dog\n",
      "File: cat_375.jpg, Prediction: Dog\n",
      "File: cat_384.jpg, Prediction: Cat\n",
      "File: cat_395.jpg, Prediction: Dog\n",
      "File: cat_417.jpg, Prediction: Cat\n",
      "File: cat_418.jpg, Prediction: Cat\n",
      "File: cat_422.jpg, Prediction: Cat\n",
      "File: cat_430.jpg, Prediction: Cat\n",
      "File: cat_433.jpg, Prediction: Cat\n",
      "File: cat_446.jpg, Prediction: Cat\n",
      "File: cat_464.jpg, Prediction: Dog\n",
      "File: cat_468.jpg, Prediction: Dog\n",
      "File: cat_473.jpg, Prediction: Cat\n",
      "File: cat_496.jpg, Prediction: Cat\n",
      "File: cat_5.jpg, Prediction: Cat\n",
      "File: cat_504.jpg, Prediction: Dog\n",
      "File: cat_520.jpg, Prediction: Cat\n",
      "File: cat_523.jpg, Prediction: Dog\n",
      "File: cat_525.jpg, Prediction: Dog\n",
      "File: cat_528.jpg, Prediction: Cat\n",
      "File: cat_538.jpg, Prediction: Dog\n",
      "File: cat_542.jpg, Prediction: Cat\n",
      "File: cat_545.jpg, Prediction: Dog\n",
      "File: cat_551.jpg, Prediction: Cat\n",
      "File: cat_56.jpg, Prediction: Cat\n",
      "File: cat_564.jpg, Prediction: Cat\n",
      "File: cat_574.jpg, Prediction: Dog\n",
      "File: cat_575.jpg, Prediction: Dog\n",
      "File: cat_583.jpg, Prediction: Dog\n",
      "File: cat_585.jpg, Prediction: Dog\n",
      "File: cat_586.jpg, Prediction: Dog\n",
      "File: cat_587.jpg, Prediction: Dog\n",
      "File: cat_595.jpg, Prediction: Dog\n",
      "File: cat_60.jpg, Prediction: Dog\n",
      "File: cat_88.jpg, Prediction: Cat\n",
      "File: cat_94.jpg, Prediction: Cat\n",
      "File: cat_96.jpg, Prediction: Cat\n",
      "File: dog_114.jpg, Prediction: Cat\n",
      "File: dog_123.jpg, Prediction: Dog\n",
      "File: dog_124.jpg, Prediction: Dog\n",
      "File: dog_130.jpg, Prediction: Dog\n",
      "File: dog_141.jpg, Prediction: Cat\n",
      "File: dog_142.jpg, Prediction: Cat\n",
      "File: dog_147.jpg, Prediction: Dog\n",
      "File: dog_150.jpg, Prediction: Cat\n",
      "File: dog_155.jpg, Prediction: Dog\n",
      "File: dog_159.jpg, Prediction: Cat\n",
      "File: dog_168.jpg, Prediction: Dog\n",
      "File: dog_173.jpg, Prediction: Dog\n",
      "File: dog_177.jpg, Prediction: Dog\n",
      "File: dog_181.jpg, Prediction: Dog\n",
      "File: dog_191.jpg, Prediction: Cat\n",
      "File: dog_194.jpg, Prediction: Dog\n",
      "File: dog_196.jpg, Prediction: Dog\n",
      "File: dog_197.jpg, Prediction: Dog\n",
      "File: dog_211.jpg, Prediction: Cat\n",
      "File: dog_213.jpg, Prediction: Dog\n",
      "File: dog_219.jpg, Prediction: Cat\n",
      "File: dog_227.jpg, Prediction: Dog\n",
      "File: dog_229.jpg, Prediction: Dog\n",
      "File: dog_236.jpg, Prediction: Dog\n",
      "File: dog_237.jpg, Prediction: Cat\n",
      "File: dog_240.jpg, Prediction: Cat\n",
      "File: dog_244.jpg, Prediction: Cat\n",
      "File: dog_258.jpg, Prediction: Cat\n",
      "File: dog_28.jpg, Prediction: Cat\n",
      "File: dog_283.jpg, Prediction: Cat\n",
      "File: dog_302.jpg, Prediction: Dog\n",
      "File: dog_303.jpg, Prediction: Dog\n",
      "File: dog_313.jpg, Prediction: Dog\n",
      "File: dog_327.jpg, Prediction: Dog\n",
      "File: dog_344.jpg, Prediction: Dog\n",
      "File: dog_354.jpg, Prediction: Cat\n",
      "File: dog_355.jpg, Prediction: Dog\n",
      "File: dog_360.jpg, Prediction: Cat\n",
      "File: dog_364.jpg, Prediction: Cat\n",
      "File: dog_369.jpg, Prediction: Cat\n",
      "File: dog_377.jpg, Prediction: Cat\n",
      "File: dog_380.jpg, Prediction: Cat\n",
      "File: dog_398.jpg, Prediction: Cat\n",
      "File: dog_415.jpg, Prediction: Dog\n",
      "File: dog_421.jpg, Prediction: Dog\n",
      "File: dog_43.jpg, Prediction: Cat\n",
      "File: dog_44.jpg, Prediction: Dog\n",
      "File: dog_442.jpg, Prediction: Dog\n",
      "File: dog_443.jpg, Prediction: Cat\n",
      "File: dog_461.jpg, Prediction: Dog\n",
      "File: dog_462.jpg, Prediction: Cat\n",
      "File: dog_464.jpg, Prediction: Cat\n",
      "File: dog_472.jpg, Prediction: Dog\n",
      "File: dog_476.jpg, Prediction: Dog\n",
      "File: dog_482.jpg, Prediction: Cat\n",
      "File: dog_517.jpg, Prediction: Cat\n",
      "File: dog_518.jpg, Prediction: Cat\n",
      "File: dog_519.jpg, Prediction: Dog\n",
      "File: dog_520.jpg, Prediction: Dog\n",
      "File: dog_521.jpg, Prediction: Cat\n",
      "File: dog_522.jpg, Prediction: Dog\n",
      "File: dog_528.jpg, Prediction: Cat\n",
      "File: dog_534.jpg, Prediction: Cat\n",
      "File: dog_536.jpg, Prediction: Cat\n",
      "File: dog_551.jpg, Prediction: Cat\n",
      "File: dog_563.jpg, Prediction: Cat\n",
      "File: dog_59.jpg, Prediction: Dog\n",
      "File: dog_68.jpg, Prediction: Dog\n",
      "File: dog_75.jpg, Prediction: Cat\n",
      "File: dog_89.jpg, Prediction: Dog\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction for the test dataset: \")\n",
    "for filename, prediction in zip(test_filenames, y_pred):\n",
    "    label = label_mapping[prediction]\n",
    "    print(f\"File: {filename}, Prediction: {label}\")\n",
    "    for lab in os.listdir(test_dir):\n",
    "        label_dir = os.path.join(test_dir,lab)\n",
    "        for f in os.listdir(label_dir):\n",
    "            # print(f)\n",
    "            if f == filename:\n",
    "                # img = cv2.imread(os.path.join(label_dir, filename))\n",
    "                # cv2.imshow(label, img)\n",
    "            \n",
    "                # b,g,r = cv2.split(img)\n",
    "                # img_rgb = cv2.merge((r,g,b))\n",
    "                # plt.imshow(img_rgb)\n",
    "                # plt.title(label)\n",
    "                # plt.show()\n",
    "                # break\n",
    "\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f7f1b-acb5-4d28-9301-20c581be6f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
